{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_8ODB5_nC0p9mh9wl3wGY3xxD5L_rLV5","timestamp":1729851816516},{"file_id":"1dW5MRRaLDxPEXYiz3xFiIYSIw9F5SiGI","timestamp":1729759927294}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Practical 2\n","\n","## Preliminary\n","\n","Load the required libraries and set defaults"],"metadata":{"id":"nIE9-BRo5IYy"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","from sklearn.datasets import load_wine\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import (\n","    LinearRegression,\n","    LogisticRegression,\n",")\n","from sklearn.metrics import (\n","    accuracy_score,\n","    classification_report,\n","    confusion_matrix,\n","    mean_squared_error,\n","    r2_score,\n",")\n","from sklearn.model_selection import (\n","    cross_val_score,\n","    GridSearchCV,\n","    train_test_split,\n",")\n","from sklearn.naive_bayes import (\n","    GaussianNB,\n","    MultinomialNB,\n",")\n","from sklearn.neighbors import (\n","    KNeighborsClassifier,\n","    KNeighborsRegressor,\n",")\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.tree import (\n","    DecisionTreeClassifier,\n","    plot_tree,\n",")\n","\n","sns.set_theme()\n","seed = 42"],"metadata":{"id":"D3LsvXm67XNx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 1: Validation Approaches"],"metadata":{"id":"E0RpYViR2V74"}},{"cell_type":"markdown","source":["We will explore the use of the validation set approach in order to estimate the test error rates that result from fitting various linear models on the `Auto` data set.\n","\n","We use the function `train_test_split()` to split the data into training and validation sets. As there are $392$ observations, we split into two equal sets of size $196$ using the argument `test_size=196`.\n","\n","It is generally a good idea to set a random seed when performing operations like this that contain an element of randomness, so that the results obtained can be reproduced precisely at a later time. We set the random seed of the splitter with the argument `random_state=seed`."],"metadata":{"id":"H2kw52KXAS_7"}},{"cell_type":"code","source":["# load data set\n","path = 'https://github.com/vladoxNCL/ml_course/raw/main/Auto.csv'\n","df = pd.read_csv(path)\n","\n","# change horsepower type to float and fix missing values\n","df['horsepower'] = df['horsepower'].replace('?', np.nan)\n","df['horsepower'] = df['horsepower'].astype(float)\n","hp_median = df['horsepower'].median()\n","df['horsepower'] = df['horsepower'].fillna(hp_median)\n","\n","# add quadratic hp feature\n","df['horsepower^2'] = df['horsepower'] ** 2"],"metadata":{"id":"WgvssbBE2YJj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we can fit a linear regression using only the observations corresponding to the training set `df_train`:"],"metadata":{"id":"xgnJATnrBGjY"}},{"cell_type":"code","source":["predictors = ['horsepower', 'horsepower^2']\n","response = 'mpg'\n","reg = LinearRegression()\n","\n","# split data into training and validation\n","X_train, X_valid, y_train, y_valid = train_test_split(\n","    df[predictors],\n","    df[response],\n","    test_size=196,\n","    random_state=seed,\n",")\n","\n","reg.fit(X_train, y_train)\n","y_train_pred = reg.predict(X_train)\n","y_valid_pred = reg.predict(X_valid)\n","\n","print(f'Training MSE: {mean_squared_error(y_train, y_train_pred)}')\n","print(f'Validation MSE: {mean_squared_error(y_valid, y_valid_pred)}')"],"metadata":{"id":"o8jYJUcuBF4E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Cross-Validation\n","\n","Lets now check the MSE using 5-Fold, 10-Fold, and Leave-One-Out (LOO) cross-validation.\n","\n","For this, we will use `sklearn`'s `cross_val_score()` function:"],"metadata":{"id":"4taZ3x4IE7Bj"}},{"cell_type":"code","source":["folds = {\n","    '5-Fold': 5,\n","    '10-Fold': 10,\n","    'LOO': df.shape[0],\n","}\n","\n","for key, val in folds.items():\n","    scores = cross_val_score(\n","        reg, df[predictors], df[response],\n","        cv=val, scoring='neg_mean_squared_error',\n","    )\n","    print(f'{key}-Fold MSE: {-scores.mean()}')"],"metadata":{"id":"HeMmcYMxEO7x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The CV approach gives a better estimation of real-world test performance, as all of the data is being utilised."],"metadata":{"id":"GP9avqUOE2fR"}},{"cell_type":"markdown","source":["\n","### Hands On\n","\n","For the `Credit` data set, predict `Balance` from the remaining features using KNN regression. Some of these features are categorical, and will need to be (one-hot) encoded first.\n","\n","Use **5-Fold cross-validation** to find the best $K \\in \\{1, 2, \\dots, 10\\}$ with respect to **R^2 Score**."],"metadata":{"id":"Ebsuoc-KGonK"}},{"cell_type":"code","source":["path = 'https://github.com/vladoxNCL/ml_course/raw/main/Credit.csv'\n","df = pd.read_csv(path)\n","\n","# your code here"],"metadata":{"id":"NJpVIT41Gmo6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part 2: Classification\n","\n","In class, we learnt about a few different classification models:\n","\n","1. Logistic regression\n","2. KNN\n","3. Na√Øve Bayes\n","4. Decision trees\n","5. Ensemble methods (e.g., random forests)\n","6. SVCs\n","\n","Lets compare their performance on the `Default` dataset to predict `default` from `student`, `balance`, and `income`, using 5-Fold CV to select the best model.\n"],"metadata":{"id":"1WbKb0SX6dPl"}},{"cell_type":"code","source":["path = 'https://github.com/vladoxNCL/ml_course/raw/main/Default.csv'\n","\n","df = pd.read_csv(path)\n","for col in ['default', 'student']:\n","    df[col] = df[col].map({'No': 0, 'Yes': 1})\n","df.head()"],"metadata":{"id":"FPDGDNdjLBFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = ['student', 'balance', 'income']\n","response = 'default'\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df[preds],\n","    df[response],\n","    test_size=0.1,\n","    random_state=seed,\n",")\n","\n","clfs = {\n","    'LR': make_pipeline(StandardScaler(), LogisticRegression(random_state=seed)),\n","    'KNN': make_pipeline(StandardScaler(), KNeighborsClassifier()),\n","    'GNB': make_pipeline(StandardScaler(), GaussianNB()),\n","    'DT': DecisionTreeClassifier(random_state=seed),\n","    'RF': RandomForestClassifier(random_state=seed),\n","    'SVC': make_pipeline(StandardScaler(), SVC(random_state=seed)),\n","}\n","\n","for clf_name, clf in clfs.items():\n","    scores = cross_val_score(\n","        clf, X_train, y_train,\n","        cv=5, scoring='accuracy',\n","    )\n","    clf.fit(X_train, y_train)\n","    preds = clf.predict(X_test)\n","    accu = accuracy_score(y_test, preds)\n","    print(f'{clf_name} Accuracy\\t Train CV: {scores.mean():.3f}\\t Test: {accu:.3f}')"],"metadata":{"id":"OAg-Wc7WLfNo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["All the models perform really well. However, the edge goes to **logistic regression**, since it is the most interpretable.\n","\n","\n","### Hyper-parameter tuning\n","\n","As an exercise, lets try to improve the accuracy of **random forests** and **SVMs** through hyper-parameter tuning:"],"metadata":{"id":"6WOZgQ2gMgQ9"}},{"cell_type":"code","source":["# set up the model and hyperparameter grid\n","rf_clf = RandomForestClassifier(random_state=seed)\n","param_grid = {\n","    'n_estimators': list(range(1, 10)),\n","    'max_depth': list(range(1, 10)),\n","}\n","\n","# perform cross-validation and hyperparameter tuning on the training set\n","grid_search = GridSearchCV(rf_clf, param_grid, cv=5)\n","grid_search.fit(X_train, y_train)\n","\n","# evaluate the model on the test set\n","y_pred = grid_search.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","\n","# best hyperparameters and cross-validation score\n","print(f'Best Parameters: {grid_search.best_params_}')\n","print(f'Best CV Score: {grid_search.best_score_}')\n","print(f'Test Accuracy: {acc:.3f}')"],"metadata":{"id":"-AgExl_RMYH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svc_clf = make_pipeline(StandardScaler(), SVC(random_state=seed))\n","param_grid = {\n","    'svc__C': [0.001, 0.01, 0.1, 1, 10],\n","    'svc__kernel': ['linear', 'rbf', 'poly'],\n","}\n","\n","# perform cross-validation and hyperparameter tuning on the training set\n","grid_search = GridSearchCV(svc_clf, param_grid, cv=5)\n","grid_search.fit(X_train, y_train)\n","\n","# evaluate the model on the test set\n","y_pred = grid_search.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","\n","# Best hyperparameters and cross-validation score\n","print(f'Best Parameters: {grid_search.best_params_}')\n","print(f'Best CV Score: {grid_search.best_score_}')\n","print(f'Test Accuracy: {acc:.3f}')"],"metadata":{"id":"s1UkxbMF8F0i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hyper-parameter tuning improved the performance of both RF and SVC. However, their performance didn't match **logistic regression**, which should still be preferred due to its interpretability.\n","\n","Lets see what info we can get from the LR model:"],"metadata":{"id":"2cDmhMkaWfoX"}},{"cell_type":"code","source":["clf = LogisticRegression(random_state=seed)\n","clf.fit(X_train, y_train)\n","preds = clf.predict(X_test)\n","print('Coefficients:')\n","for feat, coef in zip(X_test.columns, clf.coef_[0]):\n","    print(f'{feat}: {coef:.3f}')"],"metadata":{"id":"vPDYP2Lj-KqJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This tells us that `student` is **negatively** correlated with defaulting, while `balance` is **positively** correlated with defaulting (although to a lesser extent), and `income` is *uncorrelated* with defaulting.\n","\n","Another explainable model is generated by decision trees:"],"metadata":{"id":"iP6xcVf3_fzR"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier(max_depth=3, random_state=seed)\n","clf.fit(X_train, y_train)\n","preds = clf.predict(X_test)\n","print(f'Decision Tree Accuracy: {accuracy_score(y_test, preds)}\\n')\n","\n","imps = clf.feature_importances_\n","print('Feature Importances:')\n","for feat, imp in zip(X_train.columns, imps):\n","    print(f'{feat}\\t {imp:.4f}')\n","print('')\n","\n","plt.figure(figsize=(10, 5))\n","plot_tree(clf, feature_names=X_train.columns, filled=True);"],"metadata":{"id":"XX-EnoNDAFZ4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For this model, `balance` is the most important feature, followed by `income` and finally `student` is not important.\n","\n","The colours in the plot represent the **classes**: *red* means $0$ (don't default) and *blue* means $1$ (default)."],"metadata":{"id":"l0ERBuJwBPix"}},{"cell_type":"markdown","source":["## Hands On\n","\n","Use the *Wine* dataset from scikit-learn and the Support Vector Classifier (SVC) model to perform 10-fold cross-validation.\n","\n","1. Load the Wine dataset from *scikit-learn*.\n","2. Train/test split your data with a 90/10 proportion.\n","3. Create an SVC classifier.\n","4. Perform 10-fold cross-validation on the *training* data.\n","5. Print the cross-validation scores and the mean score.\n","6. Use the `GridSearchCV` function to tune the `'C'`, `'kernel'`, `'gamma'`, and `'degree'` hyper-parameters.\n","7. Verify the quality of the resulting hyper-parameters over the *test* data."],"metadata":{"id":"crxgOFYYU24a"}},{"cell_type":"code","source":["wine = load_wine()\n","wine.keys()\n","\n","# your code here"],"metadata":{"id":"1ftBi58ANuuE"},"execution_count":null,"outputs":[]}]}